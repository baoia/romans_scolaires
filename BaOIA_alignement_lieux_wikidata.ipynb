{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaOIA_alignement_lieux.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Outil d'alignement de lieux avec les informations de Wikidata**\n",
        "\n",
        "*Document d'entrée* : un fichier txt contenant la liste des lieux à aligner.\n",
        "\n",
        "*Document de sortie* : un fichier JSON contenant les informations sur les lieux récoltées via Wikidata. Ce fichier sera utile pour la création de cartes de chaleur."
      ],
      "metadata": {
        "id": "ch5CrKCkP36A"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjUeCTC0jeK0"
      },
      "source": [
        "#@markdown # Connexion du notebook à son compte Google Drive et signalement du dossier de travail :\n",
        "\n",
        "#@markdown - Lancer la cellule\n",
        "#@markdown - Cliquer sur « Exécuter malgré tout » lors de l’apparition du message d’avertissement indiquant que le notebook n’a pas été créé par Google\n",
        "#@markdown - Cliquer sur « Se connecter à Google Drive » lors de l’apparition du second message d’avertissement pour donner l’autorisation au notebook d’accéder à vos fichiers Google Drive\n",
        "#@markdown - Choisir son compte Gmail puis cliquer sur « Autoriser »\n",
        "\n",
        "#Installation des biliothèques nécessaires\n",
        "!pip install --upgrade wptools\n",
        "!pip install pgeocode\n",
        "from google.colab import drive\n",
        "import urllib.parse, urllib.request\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import wptools\n",
        "import itertools\n",
        "import pgeocode\n",
        "from pandas.plotting import table\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/\n",
        "\n",
        "#@markdown ###Indiquer le chemin vers le dossier de travail sur le Google Drive (si le dossier n'existe pas, il sera créé lors du lancement de la cellule) :\n",
        "chemin_vers_dossier_travail = '/content/drive/My Drive/lieux_wikidata/'#@param {type:\"string\"}\n",
        "\n",
        "if not os.path.exists(chemin_vers_dossier_travail):\n",
        "      os.makedirs(chemin_vers_dossier_travail)\n",
        "os.chdir(chemin_vers_dossier_travail)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKzvWeaSjc2Z"
      },
      "source": [
        "#@markdown # Récupération des informations Wikidata des lieux contenus dans le fichier texte :\n",
        "\n",
        "#@markdown ####Indiquer le chemin vers le fichier txt sur le Google Drive contenant la liste des lieux :\n",
        "chemin_vers_fichier_texte = '/content/drive/My Drive/lieux_wikidata/liste_lieux.txt' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ####Changer la langue si nécessaire (par défaut : français) :\n",
        "langue = \"fr\" #@param {type:\"string\"}\n",
        "#@markdown ####Si la détection des lieux  n'est pas assez précise, descendre le seuil à 0.8 (moins de noms vont être identifiés). Dans le cas contraire, monter le seuil à 1.0 :\n",
        "seuil = \"1.0\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ####Indiquer le nom du fichier JSON créé :\n",
        "nom_fichier_json = 'infos_lieux.json' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def CallWikifier(text, lang=langue, threshold=float(seuil)): \n",
        "  # Thresold = taux de sureté. 0.8 = sûr que le résultat est exact; mais peu de résultat.\n",
        "  # 1 = tous les résultats mais certains faux résultats\n",
        "    # Url de demande:\n",
        "    data = urllib.parse.urlencode([\n",
        "        (\"text\", text), (\"lang\", lang),\n",
        "        (\"userKey\", \"nqvsutgqswvfmrcvyxjtopvpiukjtp\"),\n",
        "        (\"pageRankSqThreshold\", \"%g\" % threshold), (\"applyPageRankSqThreshold\", \"true\"),\n",
        "        (\"nTopDfValuesToIgnore\", \"200\"), (\"nWordsToIgnoreFromList\", \"200\"),\n",
        "        (\"wikiDataClasses\", \"true\"), (\"wikiDataClassIds\", \"false\"),\n",
        "        (\"support\", \"true\"), (\"ranges\", \"false\"), (\"minLinkFrequency\", \"4\"),\n",
        "        (\"includeCosines\", \"false\"), (\"maxMentionEntropy\", \"3\")\n",
        "        ])\n",
        "    url = \"http://www.wikifier.org/annotate-article\"\n",
        "    # Appel de Wikifier \n",
        "    req = urllib.request.Request(url, data=data.encode(\"utf8\"), method=\"POST\")\n",
        "    with urllib.request.urlopen(req, timeout = 100) as f:\n",
        "        global response\n",
        "        response = f.read()\n",
        "        response = json.loads(response.decode(\"utf8\"))\n",
        "\n",
        "\n",
        "# Création des listes et dictionnaires qui vont contenir les informations \n",
        "# récupérées grâce à l'identifiant unique Wikidata.\n",
        "donnees = {}\n",
        "nom = []\n",
        "type_lieu = []\n",
        "latitude = []\n",
        "longitude = []\n",
        "longitude = []\n",
        "description = []\n",
        "document = []\n",
        "region = []\n",
        "code_postal = []\n",
        "\n",
        "file = chemin_vers_fichier_texte\n",
        "with open(file, \"r\") as g:\n",
        "    lieux_corpus = g.read()\n",
        "\n",
        "# Pour chaque lieu, appel de la fonction Callwikifier \n",
        "# Récupération des informations: type de lieu, région, code postal,\n",
        "# latitude, longitude, description, document et enregistrement sous\n",
        "# forme de dictionnaire\n",
        "\n",
        "CallWikifier(text=lieux_corpus)\n",
        "base = os.path.basename(file)\n",
        "for annotation in response[\"annotations\"]: ## pour chaque réponse:\n",
        "    try:\n",
        "      itemid = annotation[\"wikiDataItemId\"]\n",
        "      page = wptools.page(wikibase=itemid, lang=\"fr\")\n",
        "      page.get_wikidata()\n",
        "      page.get_parse()\n",
        "      infobox = page.data['infobox']\n",
        "      if infobox is not None:\n",
        "        latitude = infobox.get(\"latitude\")\n",
        "        nom = infobox.get(\"nom\")\n",
        "        type_lieu = infobox.get(\"type\")\n",
        "        if type_lieu is None: \n",
        "          type_lieu = page.data['what']\n",
        "        else:\n",
        "          type_lieu = infobox.get(\"type\")\n",
        "        latitude = infobox.get(\"latitude\")\n",
        "        longitude = infobox.get(\"longitude\")\n",
        "        description = page.data[\"description\"]\n",
        "        tout=page.data['wikidata']\n",
        "        code_postal = tout.get(\"code postal (P281)\")\n",
        "        if code_postal is not None:\n",
        "          nomi = pgeocode.Nominatim('fr')\n",
        "          if type(code_postal) is list:\n",
        "            info = nomi.query_postal_code(code_postal[0])\n",
        "            region = str(info[\"state_name\"])\n",
        "          else: \n",
        "            info = nomi.query_postal_code(code_postal)\n",
        "            region = str(info[\"state_name\"])\n",
        "        else:\n",
        "          code_postal = None\n",
        "      else:\n",
        "        pass\n",
        "      donnees[nom] = {\"Type de lieu\" : type_lieu, \"Région\": region, \"Code Postal\": code_postal,\n",
        "                              \"Latitude\" : latitude, \"Longitude\" : longitude, \"Description\": description, \"Document\": base}\n",
        "      print(donnees)\n",
        "    except KeyError as guh:\n",
        "      pass\n",
        "                    \n",
        "with open(nom_fichier_json, \"a\") as gjoi:\n",
        "  json.dump(donnees, gjoi, indent=4, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}