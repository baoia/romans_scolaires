{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaOIA_liste_informations_wikidata.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BfEv0i4Qa14"
      },
      "source": [
        "# **Outil de récupération de la liste des informations disponibles dans Wikidata pour un terme de recherche**\n",
        "\n",
        "Wikidata est une base de connaissances hébergée par la Wikimedia Foundation. Elle permet de centraliser les données utilisées par différents projets Wikimedia. Cet outil est donc utile pour récupérer le maximum d'informations à partir d'un mot clé en questionnant différentes bases de données.\n",
        "\n",
        "*Entrée* : un terme de recherche comme une personne, un lieu, un monument, une oeuvre, etc.\n",
        "\n",
        "*Document de sortie* : un fichier texte contenant les informations disponibles dans Wikidata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mzu-JR2Q1AE"
      },
      "source": [
        "#@markdown # Connexion du notebook à son compte Google Drive et signalement du dossier de travail :\n",
        "\n",
        "#@markdown - Lancer la cellule\n",
        "#@markdown - Cliquer sur « Exécuter malgré tout » lors de l’apparition du message d’avertissement indiquant que le notebook n’a pas été créé par Google\n",
        "#@markdown - Cliquer sur « Se connecter à Google Drive » lors de l’apparition du second message d’avertissement pour donner l’autorisation au notebook d’accéder à vos fichiers Google Drive\n",
        "#@markdown - Choisir son compte Gmail puis cliquer sur « Autoriser »\n",
        "''' \n",
        "Google Colab notebook.\n",
        "Python == 3.7.11\n",
        "\n",
        "BaOIA - La Contemporaine - Université de Nanterre\n",
        "'''\n",
        "\n",
        "## Installation des bibliothèques et connexion au compte Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import itertools\n",
        "import json\n",
        "import urllib.parse, urllib.request, json\n",
        "import collections\n",
        "from collections import Counter\n",
        "!pip install wptools==0.4.17\n",
        "import wptools\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/\n",
        "\n",
        "#@markdown ###Indiquer le chemin vers le dossier de travail sur le Google Drive (si le dossier n'existe pas, il sera créé lors du lancement de la cellule) :\n",
        "chemin_vers_le_dossier_de_travail = '/content/drive/My Drive/wikidata/'#@param {type:\"string\"}\n",
        "\n",
        "if not os.path.exists(chemin_vers_le_dossier_de_travail):\n",
        "      os.makedirs(chemin_vers_le_dossier_de_travail)\n",
        "os.chdir(chemin_vers_le_dossier_de_travail)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpzEWYIyRBFG"
      },
      "source": [
        "#@markdown # Récupération des informations Wikidata suivant le(s) terme(s) recherché(s) :\n",
        "\n",
        "#@markdown ####Indiquer le mot clé à rechercher :\n",
        "mot_cle = \"Jean Arp\" #@param {type:\"string\"}\n",
        "#@markdown ####Changer la langue si nécessaire (par défaut : français) :\n",
        "langue = \"fr\" #@param {type:\"string\"}\n",
        "#@markdown ####Si la détection du mot clé n'est pas assez précise, descendre le seuil à 0.8. Dans le cas contraire, monter le seuil à 1.0 :\n",
        "seuil = \"1.0\" #@param {type:\"string\"}\n",
        "\n",
        "def CallWikifier(text, lang=langue, threshold=float(seuil)): \n",
        "  # Thresold = taux de sureté. 0.8 = sûr que le résultat est exact; mais peu de résultat.\n",
        "  # 1 = tous les résultats mais certains faux résultats\n",
        "    # Url de demande:\n",
        "    data = urllib.parse.urlencode([\n",
        "        (\"text\", text), (\"lang\", lang),\n",
        "        (\"userKey\", \"nqvsutgqswvfmrcvyxjtopvpiukjtp\"),\n",
        "        (\"pageRankSqThreshold\", \"%g\" % threshold), (\"applyPageRankSqThreshold\", \"true\"),\n",
        "        (\"nTopDfValuesToIgnore\", \"200\"), (\"nWordsToIgnoreFromList\", \"200\"),\n",
        "        (\"wikiDataClasses\", \"true\"), (\"wikiDataClassIds\", \"false\"),\n",
        "        (\"support\", \"true\"), (\"ranges\", \"false\"), (\"minLinkFrequency\", \"4\"),\n",
        "        (\"includeCosines\", \"false\"), (\"maxMentionEntropy\", \"3\")\n",
        "        ])\n",
        "    url = \"http://www.wikifier.org/annotate-article\"\n",
        "    # Appel de Wikifier \n",
        "    req = urllib.request.Request(url, data=data.encode(\"utf8\"), method=\"POST\")\n",
        "    with urllib.request.urlopen(req, timeout = 500) as f:\n",
        "        global response\n",
        "        response = f.read()\n",
        "        response = json.loads(response.decode(\"utf8\"))\n",
        "        print(response)\n",
        "    # Sortie des annotations:\n",
        "    #@markdown ####Indiquer le nom du fichier créé  avec les informations récoltées grâce à Wikidata :\n",
        "    infos_wikidata = '/content/drive/My Drive/wikidata/infos_wikidata.txt'#@param {type:\"string\"}\n",
        "    with open(infos_wikidata, \"w\") as outfile:\n",
        "        for annotation in response[\"annotations\"]:\n",
        "          itemid = annotation[\"wikiDataItemId\"] \n",
        "          page = wptools.page(wikibase=itemid, lang=\"fr\")\n",
        "          page.get_wikidata()\n",
        "          page.get_parse()\n",
        "          infobox = page.data['infobox']\n",
        "          nom = infobox.get(\"nom\")\n",
        "          tout = page.data['wikidata']\n",
        "        json.dump(tout, outfile, indent=4, ensure_ascii=False)\n",
        "\n",
        "CallWikifier(text=mot_cle)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
